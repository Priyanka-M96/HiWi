        ---
title: "R Notebook"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(mlr)

mlr_data <- as.data.frame(scale(df[,4:126]))
mlr_data$label <- factor(df$label)

NAN_col <- sapply(mlr_data, function(x) all(is.nan(x)))
mlr_data <- mlr_data[,!NAN_col]

mlr_data <- normalizeFeatures(mlr_data,method = "scale")
task <- makeClassifTask(data = mlr_data,target = "label")
rdesc = makeResampleDesc("LOO")

```


```{r}

set.seed(123)
lrn <- makeLearner("classif.randomForest",predict.type = "prob")

rf_param <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry",lower = 3,upper = 8)
)

rancontrol <- makeTuneControlGrid(tune.threshold = TRUE)
rf_tune <- tuneParams(learner = lrn, resampling = rdesc,task = task, par.set = rf_param, control = rancontrol,measure = acc)


```


```{r}

lrn <- makeLearner("classif.randomForest",predict.type="prob",predict.threshold=rf_tune$threshold,par.vals= rf_tune$x)

res <- resample(lrn,task,rdesc,show.info = FALSE,models = TRUE,measures = list(mlr::acc,mlr::brier))
res
```


```{r}

caret::confusionMatrix(res$pred$data$truth,res$pred$data$response)

```
CFS
```{r}
library(FSelector)

df_cfs <- as.data.frame(scale(df[,4:126]))
df_cfs$label <- df$label

res <- cfs(label ~ . , df_cfs)
print(res)
  
  for (i in as.character(res)) {
    boxplot(
      df_cfs[,i] ~ label ,
      df_cfs ,
      ylim = c(-1, 3),
      col = c('tomato', 'turquoise'),
      main = "Correlation based Feature Selection",
      xlab = "label",
      ylab = i
    )
  }

```

```{r}

cfs_data <- df_cfs[,res]
cfs_data$label <- df_cfs$label

NAN_col <- sapply(cfs_data, function(x) all(is.nan(x)))
cfs_data <- cfs_data[,!NAN_col]

cfs_data <- normalizeFeatures(cfs_data,method = "scale")
task_cfs <- makeClassifTask(data = cfs_data,target = "label")
rdesc_cfs = makeResampleDesc("LOO")

```


```{r}
set.seed(123)
lrn_cfs <- makeLearner("classif.randomForest",predict.type = "prob")

rf_param <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry",lower = 3,upper = 8)
)

rancontrol <- makeTuneControlGrid(tune.threshold = TRUE)
rf_tune <- tuneParams(learner = lrn_cfs, resampling = rdesc_cfs,task = task_cfs, par.set = rf_param, control = rancontrol,measure = acc)


```


```{r}

lrn_cfs <- makeLearner("classif.randomForest",predict.type="prob",predict.threshold=rf_tune$threshold,par.vals= rf_tune$x)

res_cfs <- resample(lrn_cfs,task_cfs,rdesc_cfs,show.info = FALSE,models = TRUE,measures = list(mlr::acc,mlr::brier))

res_cfs
```


```{r}

caret::confusionMatrix(res_cfs$pred$data$truth,res_cfs$pred$data$response)

```



```{r}
library(GGally)

GGally::ggcorr(mlr_data,hjust = 1.00,layout.exp = 20,size = 3,method = c("all.obs","spearman"))

```

```{r}

library(caret)

cor_full = cor(mlr_data[,-c(which(colnames(mlr_data) == 'label'))],method = "spearman")
hc <- caret::findCorrelation(cor_full,cutoff = 0.95)
hc <- sort(hc)
reduced_Data_new = mlr_data[,-c(hc)]
print (reduced_Data_new)

reduced_Data_new$label <- mlr_data$label

```

IG

```{r}

#task <- makeClassifTask(data = reduced_Data_new,target = "label")

fil_val_new_2 <- generateFilterValuesData(task,method = c("FSelectorRcpp_information.gain"))
fil_val_new_2


```

```{r}

library(tidyverse)
library(ggplot2)

#example_data <- table(fil)
y <- data.frame(fil_val_new_2$data$name,fil_val_new_2$data$value)
y <- y[which(y$fil_val_new_2.data.value != 0),]
y$fil_val_new_2.data.name <- factor(y$fil_val_new_2.data.name, levels = y$fil_val_new_2.data.name[order(y$fil_val_new_2.data.value)])

y %>% 
    ggplot(aes(x = fil_val_new_2.data.name, y = fil_val_new_2.data.value)) +
    geom_col() + coord_flip() 



```

```{r}

library(mlr)

IG_data_new <- mlr_data[,which(fil_val_new_2$data$value != 0)]
IG_data_new$label <- mlr_data$label
task.2_new <- makeClassifTask(data = IG_data_new,target = "label")
rdesc = makeResampleDesc("LOO")

```


```{r}
set.seed(123)
lrn <- makeLearner("classif.randomForest",predict.type = "prob")

rf_param <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry",lower = 3,upper = 8)
)

rancontrol <- makeTuneControlGrid(tune.threshold = TRUE)
rf_tune <- tuneParams(learner = lrn, resampling = rdesc,task = task.2_new, par.set = rf_param, control = rancontrol,measure = acc)

```

```{r}
library(mlr)

lrn_allF_IG.new <- makeLearner("classif.randomForest",predict.type = "prob",predict.threshold = rf_tune$threshold,par.vals = rf_tune$x)

mod_IG.2.new <- mlr::train(lrn_allF_IG.new,task.2_new)

res_2_IG.new <- resample(lrn_allF_IG.new,task.2_new,rdesc,models = TRUE,show.info = TRUE)
res_2_IG.new
```

```{r}
caret::confusionMatrix(res_2_IG.new$pred$data$truth,res_2_IG.new$pred$data$response)

```
Chi

```{r}

fil_val3_new <- generateFilterValuesData(task,method = c("FSelector_chi.squared"))
fil_val3_new

```

```{r}

library(tidyverse)
library(ggplot2)

#example_data <- table(fil)
z <- data.frame(fil_val3_new$data$name,fil_val3_new$data$value)
z <- z[which(z$fil_val3_new.data.value != 0),]
z$fil_val3_new.data.name <- factor(z$fil_val3_new.data.name, levels = z$fil_val3_new.data.name[order(z$fil_val3_new.data.value)])

z %>% 
    ggplot(aes(x = fil_val3_new.data.name, y = fil_val3_new.data.value)) +
    geom_col() + coord_flip() 

```

```{r}
library(mlr)

Chi_data_new <- mlr_data[,which(fil_val3_new$data$value != 0)]
Chi_data_new$label <- mlr_data$label
task.3_new <- makeClassifTask(data = Chi_data_new,target = "label")
rdesc = makeResampleDesc("LOO")
```


```{r}

set.seed(123)
lrn <- makeLearner("classif.randomForest",predict.type = "prob")

rf_param <- makeParamSet(
makeIntegerParam("ntree",lower = 50, upper = 500),
makeIntegerParam("mtry",lower = 3,upper = 8)
)

rancontrol <- makeTuneControlGrid(tune.threshold = TRUE)
rf_tune.3 <- tuneParams(learner = lrn, resampling = rdesc,task = task.3_new, par.set = rf_param, control = rancontrol,measure = acc)

```

```{r}

lrn_allF_Chi_new <- makeLearner("classif.randomForest",predict.type = "prob",predict.threshold = rf_tune.3$threshold,par.vals = rf_tune.3$x)

mod_Chi_new <- mlr::train(lrn_allF_Chi_new,task.3_new)

res_2_Chi_new <- resample(lrn_allF_Chi_new,task.3_new,rdesc,models = TRUE,show.info = TRUE)
res_2_Chi_new
```

```{r}

caret::confusionMatrix(res_2_Chi_new$pred$data$truth,res_2_Chi_new$pred$data$response)

```
Random

```{r}

lrn_Random <- makeLearner("classif.randomForest",predict.type="prob",predict.threshold=rf_tune$threshold,par.vals= rf_tune$x)

lrn_allF_3<-makeFeatSelWrapper(lrn_Random,resampling=rdesc,control=makeFeatSelControlRandom(maxit= 10L),show.info=FALSE)
mod_3 <- mlr::train(lrn_allF_3,task = task)

res_3 <- resample(lrn_allF_3,task,rdesc,models = TRUE,show.info = TRUE)
res_3
sfeat_3 <- getFeatSelResult(mod_3)
sfeat_3

```

```{r}

library(iml)
predictor_3 <- Predictor$new(mod_3, data = df[,sfeat_3$x], y = df$label)
imp <- FeatureImp$new(predictor_3, loss = "ce")
plot(imp)


```

```{r}

caret::confusionMatrix(res_3$pred$data$truth,res_3$pred$data$response)

```

GA

```{r}

lrn_GA <- makeLearner("classif.randomForest",predict.type="prob",predict.threshold=rf_tune$threshold,par.vals= rf_tune$x)

lrn_allF_4_new <- makeFeatSelWrapper(lrn_GA,resampling = rdesc,control = makeFeatSelControlGA(maxit = 10L),show.info = FALSE)
mod_4 <- mlr::train(lrn_allF_4_new,task = task)

sfeat_4 <- getFeatSelResult(mod_4)
sfeat_4

```


```{r}

library(iml)
predictor_4 <- Predictor$new(mod_4, data = df[,sfeat_4$x], y = df$label)
imp <- FeatureImp$new(predictor_4, loss = "ce")
plot(imp)

```

```{r}

res_4 <- resample(lrn_allF_4_new,task,rdesc,models = TRUE,show.info = TRUE)
res_4
```

```{r}

caret::confusionMatrix(res_4$pred$data$truth,res_4$pred$data$response)

```


